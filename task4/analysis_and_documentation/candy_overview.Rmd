---
title: "Candy Overview"
output: html_notebook
---

```{r}
library(tidyverse)
library(here)
library(ggplot2)
```

```{r}
# Read in the cleaned data
bb_candy_bind_clean <- read_csv(here("data/clean_data/bb_candy_bind_clean.csv"))
```

# Boing Boing Candy Analysis

## The Raw Data

The *raw data* came in the form of 3 .xlsx files. These contained data from 3 years worth of trick or treating information. They were all in __wide format__ and filled with **NA values**. There was a lot of data that was not required for the analysis. There were a couple of columns with problematic data which required a lot of cleaning. In particular the *country* column in the 2016 and 2017 table had many different spellings of the country names required. Also the age columns were of type __character__ and had a lot of values which sat outside my chosen range.

## Assumptions

My first assumption was that I would have to trim off the multiple columns which were not required for the analysis. I also knew that I would have to __pivot__ the table/tables to **long format** at some point. This massively reduced the number of columns and made the data easier to read. Also, I knew I had to __bind__ the tables. I decided that I would do a lot of the **cleaning** of the column headers before binding and then clean the information in the columns after, such as country names and gender.

## Cleaning Process Overview

I have four .R scripts containing all of my cleaning data. I have one for each one of the years (2015, 2016, 2017), then a final cleaning script with all of the data in one table (bb_candy_bind_clean.csv). At the end of this script I wrote the final cleaned table to a `.csv` file ready for analysis. Here is an overview of my cleaning steps.

**Cleaning processes for bb_candy_2015, 2016 & 2017**

- Read in the .xlsx file and assign it
- Use the `clean_names()` function to tidy up the column headers
- Use `rename()` and `str_remove()` to further tidy up column names
- Change the column __type__ using `mutate()` and `as.numeric()`
- Amend the date as we only required the **year** for analysis
- Remove all of the columns which we do not require

 **Cleaning processes for bb_candy_bind_clean.R**
 
- Read in the separate years
- Connect the data using `bind_rows()`
- Tidy the **countries** all together
- Use `str_to_lower()` and `str_detect()` to change the numbers to __NA__
- Remove the punctuation and use __regex__ to condense the **countries**
- As I only need certain countries, change the countries not required to **"other"**
- Set a range for the **age** column
- `Pivot` the data to __long format__ creating a `candy` and `rating` column
- Tidy the names of some of the `candy`
- Drop the __NA values__ from the `rating` column as we do not need information on `candy` which was not rated
- Tidy the `gender` column for analysis
- Write the final cleaned dataset to a `.csv` file


## Task Analysis

___1. What is the total number of candy ratings given across the three years. (Number of candy ratings, not the number of raters. Donâ€™t count missing values)___

- Every row in the dataset represents a rating as the __NA values__ have already been removed. Therefore the total number of ratings is just the number of rows, which is 640459.
```{r}
n_candy_ratings <- bb_candy_bind_clean %>% 
  summarise(n())
n_candy_ratings
```

___2. What was the average age of people who are going out trick or treating?___

- **Filtered** to only show the people who went trick or treating. Dropped the __NA values__ as they will hinder the `summarise`. Found the `mean` of all of the ages left and **rounded** to 2 decimal places, giving us 35.28.
```{r}
avg_age_t_or_t <- bb_candy_bind_clean %>% 
  filter(going_trick_or_treating == "Yes") %>% 
  drop_na(age) %>% 
  summarise(mean_age = round(mean(age), 2))
avg_age_t_or_t
```
___3. What was the average age of people who are not going trick or treating?___

- Similar process to the previous question. The `mean` age of people not going trick or treating is 39.24 which is what we would expect as usually younger people go trick or treating.
```{r}
avg_age_not_t_or_t <- bb_candy_bind_clean %>% 
  filter(going_trick_or_treating == "No") %>% 
  drop_na(age) %>% 
  summarise(round(mean(age), 2))
avg_age_not_t_or_t
```

___4. For each of joy, despair and meh, which candy bar received the most of these ratings?___

- **Grouped by** `rating` and summarised a count of the number of each rating. Surprisingly more candies brought __despair__ than **joy**.
```{r}
n_of_each_rating <- bb_candy_bind_clean %>% 
  group_by(rating) %>% 
  summarise(n_ratings = n())
n_of_each_rating
```

___5. How many people rated Starburst as despair?___

- **Filtered** by `candy` and `rating` then **summarised** with a count of the people who rated starburst as despair. This number was 1990.
```{r}
starburst_despair <- bb_candy_bind_clean %>% 
  filter(candy == "starburst",
         rating == "despair") %>% 
  summarise(n_of_starburst_despair = n())
starburst_despair
```

___For the next three questions, count despair as -1, joy as +1, and meh as 0___

- First I created a new column called `rating_no` which gave a value to each of the 3 different ratings. The *sum* of this will give us an excellent indication of what people think of the candy, by *upvoting* for **joy** and *downvoting* for **despair**. I will call this calculation `joy_vs_despair_rating`.
```{r}
bb_candy_bind_rating_system <- bb_candy_bind_clean %>% 
  mutate(rating_no = case_when(
    rating == "joy" ~ 1,
    rating == "despair" ~ -1,
    rating == "meh" ~ 0
  ))
bb_candy_bind_rating_system
```


___6. What was the most popular candy bar by this rating system for each gender in the dataset?___

- I initially **grouped_by** `candy` and `gender` to find the `sum_rating` of the `rating_no`. I then had to group by `gender` again and use **slice_max** to find the result above. This shows that _reese_s_peanut_butter_cups_ seems to be a favourite.
```{r}
bb_candy_all_gender_favs <- bb_candy_bind_rating_system %>% 
  group_by(candy, gender) %>%
  summarise(joy_vs_despair_rating = sum(rating_no)) %>% 
  group_by(gender) %>% 
  slice_max(joy_vs_despair_rating)
bb_candy_all_gender_favs
```
___7. What was the most popular candy bar in each year?___

- Similar to the previous analysis, I **grouped_by** `candy` and `year` to find the `sum_rating` of the `rating_no`. I then grouped again by year and used **slice_max()** to give me the most popular candy bar from each year.
```{r}
bb_candy_most_pop_by_year <- bb_candy_bind_rating_system %>% 
  group_by(candy, year) %>%
  summarise(joy_vs_despair_rating = sum(rating_no)) %>% 
  group_by(year) %>% 
  slice_max(joy_vs_despair_rating)
bb_candy_most_pop_by_year
```

___8. What was the most popular candy bar by this rating for people in US, Canada, UK, and all other countries?___

- Again, similar to the previous analysis. I had to **group_by** twice to give me the result above. Interestingly enough this shows a three way tie between `lindt_truffle`, `rolos` and `toblerone` as the UK's favourite candy!
```{r}
bb_candy_country_favs <- bb_candy_bind_rating_system %>% 
  group_by(candy, country) %>%
  summarise(joy_vs_despair_rating = sum(rating_no)) %>% 
  group_by(country) %>% 
  slice_max(joy_vs_despair_rating)
bb_candy_country_favs
```


## Extra Analysis

___What type of `m&m's` have the most ratings?___

- I noticed in the data that there were a lot of different types of M&Ms and I decided not to group them together as they are a stand alone product. I thought it would then be interesting to find out which M&Ms got the most `ratings` and also what brought the most **joy**.

```{r}
bb_candy_most_rated_m_ms <- bb_candy_bind_rating_system %>% 
  mutate(m_ms = str_detect(candy, "m_ms.")) %>%
  filter(m_ms == TRUE) %>% 
  group_by(candy) %>% 
  summarise(m_ms_ratings = n()) %>% 
  arrange(desc(m_ms_ratings))
bb_candy_most_rated_m_ms
```
- We can see here that Peanut M&Ms (m_ms_peanut) have the most `ratings` and also the highest `joy_vs_despair_rating`.

```{r}
bb_candy_most_pop_m_ms <- bb_candy_bind_rating_system %>% 
  mutate(m_ms = str_detect(candy, "m_ms.")) %>%
  filter(m_ms == TRUE) %>% 
  group_by(candy) %>% 
  summarise(joy_vs_despair_rating = sum(rating_no)) %>% 
  slice_max(joy_vs_despair_rating)
bb_candy_most_pop_m_ms
```


- I then thought the only way to find a fair representation of people's feelings towards M&Ms was to work out what proportion of each type brought `joy`. Here we can see that 78% of the Peanut M&Ms brought joy, confirming their place as the most favourite M&M. This also showed us that public opinion is very much divided on the Mint M&Ms, with 49% voting `joy`.

```{r}
bb_candy_joy_proportion <- bb_candy_bind_rating_system %>% 
  mutate(m_ms = str_detect(candy, "m_ms.")) %>%
  filter(m_ms == TRUE) %>% 
  group_by(candy) %>%
  mutate(rating_count = n()) %>%
  filter(rating == "joy") %>% 
  mutate(joy_sum = sum(rating_no), 
         joy_prop = round((joy_sum/rating_count), 2)) %>% 
  distinct(candy, joy_prop) %>% 
  arrange(desc(joy_prop))
bb_candy_joy_proportion
```

```{r}

x_labels <- c("Peanut", "Blue", "Green", "Red", "Mint")
joy_prop_graph <- ggplot(bb_candy_joy_proportion, 
                         aes(x = x_labels, y = joy_prop)) +
  geom_bar(stat ="identity", 
           color = "black", 
           fill = c("yellow", "blue", "green", "red", "light green")) + ggtitle("Proportion of M&M's which were rated 'joy'") + 
  xlab("Type of M&M") + 
  ylab("Proportion") +
  ylim(0, 1)
joy_prop_graph
```
